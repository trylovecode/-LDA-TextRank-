{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.复习上课内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.回答以下理论问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 请写一下TF-IDF的计算公式\n",
    " TFt,d = count(t,d)\n",
    " IDFt = log10(N / DFt)\n",
    " TF-IDF = TFt,d * IDFt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. LDA算法的基本假设是什么？\n",
    "1.原始数据根据样本均值进行分类。\n",
    "2.不同类的数据拥有相同的协方差矩阵。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 在TextRank算法中构建图的权重是如何得到的？\n",
    "权重是从某个点链接出去的数量的倒数，数量越多，权重越小。\n",
    "两个词之间的权重是这两个词向量的余弦距离。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 什么是命名实体识别？ 有什么应用场景？\n",
    "命名实体识别是指识别文本中具有特定意义的实体，包括人名、地名、组织名、动物名、植物名等等。识别出这些实体的名称，并且识别出这些实体的类别。\n",
    "命名实体识别可以用于知识图谱、文本理解、对话系统、舆情分析等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.NLP主要有哪几类任务 ？\n",
    "分类任务：文本分类，情感分类。\n",
    "生成任务：机器翻译，对话系统，文本摘要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.实践题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 手动实现TextRank算法 (在新闻数据中随机提取1条新闻训练词向量和做做法测试）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 提示：\n",
    " 1. 确定窗口，建立图链接。   \n",
    " 2. 根据公式实现算法迭代(d=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "import jieba.posseg as jp\n",
    "import jieba\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['此外自本周6月12日起除小米手机6等15款机型外其余机型已暂停更新发布含开发版体验版内测稳定版暂不受影响以确保工程师可以集中全部精力进行系统优化工作有人猜测这也是将精力主要用到MIUI9的研发之中MIUI8去年5月发布距今已有一年有余也是时候更新换代了当然关于MIUI9的确切信息我们还是等待官方消息', '骁龙835作为唯一通过Windows10桌面平台认证的ARM处理器高通强调不会因为只考虑性能而去屏蔽掉小核心相反他们正联手微软找到一种适合桌面平台的兼顾性能和功耗的完美方案报道称微软已经拿到了一些新的源码以便Windows10更好地理解biglittle架构资料显示骁龙835作为一款集成了CPUGPU基带蓝牙WiFi的SoC比传统的Wintel方案可以节省至少30的PCB空间按计划今年Q4华硕惠普联想将首发骁龙835Win10电脑预计均是二合一形态的产品当然高通骁龙只是个开始未来也许还能见到三星Exynos联发科华为麒麟小米澎湃等进入Windows10桌面平台', '此前的一加3T搭载的是3400mAh电池DashCharge快充规格为5V4A至于电池缩水可能与刘作虎所说一加手机5要做市面最轻薄大屏旗舰的设定有关按照目前掌握的资料一加手机5拥有55寸1080P三星AMOLED显示屏6G8GBRAM64GB128GBROM双1600万摄像头备货量惊喜根据京东泄露的信息一加5起售价是xx99元应该是在279928992999中的某个']\n"
     ]
    }
   ],
   "source": [
    "# 加载数据，选取前三条新闻\n",
    "data_source = \"/Users/zhangxiaonan/Desktop/article_9k.txt\"\n",
    "data = pd.read_csv(data_source, header=None)\n",
    "data = data.fillna('')\n",
    "news_content = data[0].tolist()\n",
    "print(news_content[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于LDA的TextRank的实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['起除', '小米', '手机', '机型', '机型', '已', '暂停', '更新', '发布', '含', '开发', '版', '体验版', '内测', '稳定版', '暂不', '受', '确保', '工程师', '精力', '系统优化', '精力', '用到', 'MIUI9', 'MIUI8', '发布', '距今已有', 'MIUI9', '信息', '等待', '官方消息'], ['Windows10', '桌面', '平台', '认证', 'ARM', '处理器', '高通', '只', '性能', '去', '核心', '正', '联手', '找到', '适合', '桌面', '平台', '兼顾', '性能', '功耗', '方案', '报道', '称', '拿到', '源码', 'Windows10', '更好', '理解', 'biglittle', '架构', '资料', '显示', '集成', 'CPUGPU', '基带', '蓝牙', 'WiFi', 'SoC', '传统', 'Wintel', '方案', '节省', '至少', 'PCB', '空间', '按计划', 'Q4', '华硕', '惠普', '联想', '首发', 'Win10', '电脑', '均', '形态', '产品', '高通', '也许', '见到', 'Exynos', '联发科', '华为', '麒麟', '小米', '澎湃', 'Windows10', '桌面', '平台'], ['一加', 'T', '搭载', 'mAh', '电池', 'DashCharge', '充', '规格', 'V4A', '电池', '缩水', '刘作虎', '一加', '手机', '做', '市面', '最', '大屏', '旗舰', '设定', '资料', '一加', '手机', '拥有', 'P', 'AMOLED', '显示屏', 'G8GBRAM64GB128GBROM', '双', '摄像头', '备货', '量', '京东', '泄露', '信息', '一加', '售价', 'xx99']]\n"
     ]
    }
   ],
   "source": [
    "def get_text(texts):\n",
    "    # 保留特定词性\n",
    "    flags = ('n', 'nr', 'ns', 'nt', 'eng', 'v', 'd')  # 词性\n",
    "    # 去掉停用词\n",
    "    stop_words = []\n",
    "    with open('/Users/zhangxiaonan/Desktop/百度停用词表.txt') as f:\n",
    "        for word in f.readlines():\n",
    "            stop_words.append(word.strip())\n",
    "            \n",
    "    words_list = []\n",
    "    news = ''\n",
    "    for text in texts:\n",
    "        words = [w.word for w in jp.cut(text) if w.flag in flags and w.word not in stop_words]\n",
    "        words_list.append(words)\n",
    "        \n",
    "        # 分词后的整体字符串\n",
    "#         if words:\n",
    "#             word_list.append(words)\n",
    "#     for i in word_list:\n",
    "#         for j in i:\n",
    "#             if i:\n",
    "#                 news+=j\n",
    "\n",
    "    # 返回分词后的词组list\n",
    "    return words_list\n",
    "\n",
    "words_list = get_text(news_content[:3])\n",
    "print(words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(115 unique tokens: ['MIUI8', 'MIUI9', '体验版', '信息', '内测']...) \n",
      "\n",
      "打印查看每个单词的id:\n",
      "{'MIUI8': 0, 'MIUI9': 1, '体验版': 2, '信息': 3, '内测': 4, '发布': 5, '受': 6, '含': 7, '官方消息': 8, '小米': 9, '工程师': 10, '已': 11, '开发': 12, '手机': 13, '暂不': 14, '暂停': 15, '更新': 16, '机型': 17, '版': 18, '用到': 19, '确保': 20, '稳定版': 21, '等待': 22, '精力': 23, '系统优化': 24, '起除': 25, '距今已有': 26, 'ARM': 27, 'CPUGPU': 28, 'Exynos': 29, 'PCB': 30, 'Q4': 31, 'SoC': 32, 'WiFi': 33, 'Win10': 34, 'Windows10': 35, 'Wintel': 36, 'biglittle': 37, '也许': 38, '产品': 39, '传统': 40, '兼顾': 41, '功耗': 42, '华为': 43, '华硕': 44, '去': 45, '只': 46, '均': 47, '基带': 48, '处理器': 49, '平台': 50, '形态': 51, '性能': 52, '惠普': 53, '找到': 54, '报道': 55, '拿到': 56, '按计划': 57, '方案': 58, '显示': 59, '更好': 60, '架构': 61, '核心': 62, '桌面': 63, '正': 64, '源码': 65, '澎湃': 66, '理解': 67, '电脑': 68, '称': 69, '空间': 70, '联发科': 71, '联想': 72, '联手': 73, '至少': 74, '节省': 75, '蓝牙': 76, '见到': 77, '认证': 78, '资料': 79, '适合': 80, '集成': 81, '首发': 82, '高通': 83, '麒麟': 84, 'AMOLED': 85, 'DashCharge': 86, 'G8GBRAM64GB128GBROM': 87, 'P': 88, 'T': 89, 'V4A': 90, 'mAh': 91, 'xx99': 92, '一加': 93, '京东': 94, '做': 95, '充': 96, '刘作虎': 97, '双': 98, '售价': 99, '备货': 100, '大屏': 101, '市面': 102, '拥有': 103, '搭载': 104, '摄像头': 105, '旗舰': 106, '显示屏': 107, '最': 108, '泄露': 109, '电池': 110, '缩水': 111, '规格': 112, '设定': 113, '量': 114} \n",
      "\n",
      "输出每个文档的向量:\n",
      "[[(0, 1), (1, 2), (2, 1), (3, 1), (4, 1), (5, 2), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 2), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 2), (24, 1), (25, 1), (26, 1)], [(9, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 3), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 3), (51, 1), (52, 2), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 2), (59, 1), (60, 1), (61, 1), (62, 1), (63, 3), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 1), (83, 2), (84, 1)], [(3, 1), (13, 2), (79, 1), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 4), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 1), (106, 1), (107, 1), (108, 1), (109, 1), (110, 2), (111, 1), (112, 1), (113, 1), (114, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# 生成LDA模型\n",
    "def LDA_model(words_list):\n",
    "    # Dictionary()方法遍历所有的文本，为每个不重复的单词分配一个单独的整数ID，同时收集该单词出现次数以及相关的统计信息\n",
    "    dictionary = corpora.Dictionary(words_list)\n",
    "    print(dictionary,'\\n')\n",
    "    print('打印查看每个单词的id:')\n",
    "    print(dictionary.token2id,'\\n')  # 打印查看每个单词的id\n",
    " \n",
    "    # 将dictionary转化为一个词袋\n",
    "    # doc2bow()方法将dictionary转化为一个词袋。得到的结果corpus是一个向量的列表，向量的个数就是文档数。\n",
    "    # 在每个文档向量中都包含一系列元组,元组的形式是（单词ID，词频）\n",
    "    corpus = [dictionary.doc2bow(words) for words in words_list]\n",
    "    print('输出每个文档的向量:')\n",
    "    print(corpus)  # 输出每个文档的向量\n",
    " \n",
    "    # LDA主题模型\n",
    "    # num_topics -- 必须要生成的主题个数。\n",
    "    # id2word    -- 必须LdaModel类要求我们之前的dictionary把id都映射成为字符串。\n",
    "    # passes     -- 可选模型遍历语料库的次数。遍历的次数越多，模型越精确。但是对于非常大的语料库，遍历太多次会花费很长的时间。\n",
    "    lda_model = models.ldamodel.LdaModel(corpus=corpus, num_topics=2, id2word=dictionary, passes=10)\n",
    "    return lda_model\n",
    "\n",
    "lda_model = LDA_model(words_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "打印所有topic，每个topic显示5个词:\n",
      "[(0, '0.028*\"精力\" + 0.028*\"机型\" + 0.028*\"MIUI9\" + 0.028*\"发布\" + 0.017*\"信息\"'), (1, '0.028*\"一加\" + 0.021*\"Windows10\" + 0.021*\"平台\" + 0.021*\"桌面\" + 0.015*\"手机\"')] \n",
      "\n",
      "输出topic的的词及其词的权重:\n",
      "[('精力', 0.02811364), ('机型', 0.028096432), ('MIUI9', 0.028096361), ('发布', 0.028062385), ('信息', 0.01694779)]\n"
     ]
    }
   ],
   "source": [
    "# 用 print_topic 和 print_topics 方法来查看主题\n",
    "topic_words = lda_model.print_topics(num_topics=2, num_words=5)\n",
    "print('打印所有topic，每个topic显示5个词:')\n",
    "print(topic_words,'\\n') \n",
    "\n",
    "words_list = lda_model.show_topic(0, 5)\n",
    "print('输出topic的的词及其词的权重:')\n",
    "print(words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 0.25918934), (1, 0.74081063)]]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 选取第七条新闻\n",
    "news = data[0][6]\n",
    "#print(data[0][6])\n",
    "words_ls = []\n",
    "for text in news:\n",
    "    words = [w.word for w in jp.cut(text) if w.flag in flags and w.word not in stop_words]\n",
    "    words_ls.append(words)\n",
    "\n",
    "words = [[w.word for w in jp.cut(news) if w.flag in flags and w.word not in stop_words]]\n",
    "dictionary = corpora.Dictionary(words_ls)\n",
    "text_corpus = [dictionary.doc2bow(word) for word in words]\n",
    "list(lda_model[text_corpus])\n",
    "#结果表示预测可能是第二个topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 选做 1.  提取新闻人物里的对话。(使用以上提取小数据即可）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提示：    \n",
    "1.寻找预料里具有表示说的意思。    \n",
    "2.使用语法分析提取句子结构。    \n",
    "3.检测谓语是否有表示说的意思。(手工设定，比如\"说，表达，表示\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
